./llama-server \
    --model ~/models/qwen38BThinking/Qwen3-8B-Q8_0.gguf \
    --host 127.0.0.1 \
    --port 8000 \
    --ctx-size 16384 \
    --n-gpu-layers 99 \
    -ot ".ffn_.*_exps.=CPU" \
    --seed 3407 \
    --prio 3 \
    --temp 0.6 \
    --min-p 0.0 \
    --top-p 0.95 \
    --top-k 20 \
    -no-cnv \


./llama-server \
    --model /home/t2430487/model/gpt-oss-20b-F16.gguf \
    --host 127.0.0.1 \
    --port 8000 \
    --n-gpu-layers 99 \
    --threads -1 \
    --ctx-size 16384 \
    --temp 1.0 \
    --top-p 1.0 \
    --top-k 0 \
    --chat-template-file /home/t2430487/model/gpt_oss.jinja \
    --jinja

    
    --chat-template-kwargs '{"reasoning_effort": "high"}'
    --chat-template-kwargs "{\"reasoning_effort\": \"high\"}"
